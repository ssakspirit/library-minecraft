"""
ë°ì´í„° í’ˆì§ˆ ë¶„ì„ ë° ì¶”ì²œ ê°€ëŠ¥ì„± í‰ê°€
"""
import sys
import io
import json
import random
from pathlib import Path
from collections import Counter

# Fix Windows console encoding
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')


def analyze_data_quality():
    """ë°ì´í„° í’ˆì§ˆ ë¶„ì„"""

    with open('data/resources.json', 'r', encoding='utf-8') as f:
        data = json.load(f)

    print("=" * 80)
    print("ğŸ“Š ë°ì´í„° í’ˆì§ˆ ë¶„ì„ ë¦¬í¬íŠ¸")
    print("=" * 80)

    # ê¸°ë³¸ í†µê³„
    print(f"\nâœ… ì´ ë¦¬ì†ŒìŠ¤ ìˆ˜: {len(data)}")

    # íƒ€ì…ë³„ ë¶„í¬
    types = Counter(r['type'] for r in data)
    print(f"\nğŸ“‹ íƒ€ì…ë³„ ë¶„í¬:")
    for type_name, count in types.items():
        print(f"  - {type_name}: {count}ê°œ")

    # Description ê¸¸ì´ ë¶„ì„
    desc_lengths = [len(r.get('description', '')) for r in data]
    avg_desc_length = sum(desc_lengths) / len(desc_lengths)
    print(f"\nğŸ“ Description ë¶„ì„:")
    print(f"  - í‰ê·  ê¸¸ì´: {avg_desc_length:.0f}ì")
    print(f"  - ìµœì†Œ ê¸¸ì´: {min(desc_lengths)}ì")
    print(f"  - ìµœëŒ€ ê¸¸ì´: {max(desc_lengths)}ì")

    # ë¹ˆ description ì²´í¬
    empty_desc = sum(1 for r in data if not r.get('description', '').strip())
    print(f"  - ë¹ˆ description: {empty_desc}ê°œ ({empty_desc/len(data)*100:.1f}%)")

    # Subjects ë¶„ì„
    all_subjects = []
    for r in data:
        subjects = r.get('subjects', '')
        if subjects:
            all_subjects.extend(subjects.split(','))

    subject_counts = Counter(all_subjects)
    print(f"\nğŸ¯ ê³¼ëª© ë¶„ì„ (ìƒìœ„ 10ê°œ):")
    for subject, count in subject_counts.most_common(10):
        print(f"  - {subject}: {count}ê°œ")

    # ìƒ˜í”Œ ë°ì´í„° ì¶œë ¥
    print("\n" + "=" * 80)
    print("ğŸ“„ ëœë¤ ìƒ˜í”Œ 5ê°œ")
    print("=" * 80)

    samples = random.sample(data, min(5, len(data)))
    for i, resource in enumerate(samples, 1):
        print(f"\n{i}. [{resource['type']}] {resource['title']}")
        print(f"   ê³¼ëª©: {resource.get('subjects', 'N/A')}")
        print(f"   ì„¤ëª…: {resource.get('description', 'N/A')[:150]}...")
        print(f"   URL: {resource['url']}")

    # í‚¤ì›Œë“œ ì¶”ì²œ ê°€ëŠ¥ì„± í‰ê°€
    print("\n" + "=" * 80)
    print("ğŸ¤” í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ì²œ ê°€ëŠ¥ì„± í‰ê°€")
    print("=" * 80)

    # í˜„ì¬ ë°ì´í„°ë¡œ ê°€ëŠ¥í•œ ê²ƒ
    print("\nâœ… í˜„ì¬ ë°ì´í„°ë¡œ ê°€ëŠ¥í•œ ì¶”ì²œ:")
    print("  1. ê³¼ëª© ê¸°ë°˜ í•„í„°ë§ (ë§¤ìš° ì •í™•)")
    print("  2. íƒ€ì… ê¸°ë°˜ í•„í„°ë§ (World/Challenge/Lesson)")
    print("  3. ì œëª© í‚¤ì›Œë“œ ê²€ìƒ‰ (ë³´í†µ)")
    print("  4. ì§§ì€ ì„¤ëª… ê¸°ë°˜ í‚¤ì›Œë“œ ë§¤ì¹­ (ì œí•œì )")
    print("  5. SQLite FTS5 ì „ì²´ í…ìŠ¤íŠ¸ ê²€ìƒ‰ (ë¹ ë¦„)")

    # í˜„ì¬ ë°ì´í„°ì˜ í•œê³„
    print("\nâš ï¸ í˜„ì¬ ë°ì´í„°ì˜ í•œê³„:")
    print("  1. Descriptionì´ ë„ˆë¬´ ì§§ìŒ (~100ì, ì˜ë¦¼)")
    print("  2. í•™ìŠµ ëª©í‘œ(objectives) ì—†ìŒ")
    print("  3. ë‚œì´ë„(difficulty) ì •ë³´ ì—†ìŒ")
    print("  4. ì†Œìš” ì‹œê°„(duration) ì •ë³´ ì—†ìŒ")
    print("  5. ì „ì²´ ì½˜í…ì¸ (full_content) ì—†ìŒ")

    # ê°œì„  ë°©ì•ˆ
    print("\nğŸ’¡ ì¶”ì²œ í’ˆì§ˆ ê°œì„  ë°©ì•ˆ:")
    print("  1. ì›¹ í¬ë¡¤ë§ìœ¼ë¡œ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ (crawler.py)")
    print("  2. í‚¤ì›Œë“œ ì„ë² ë”© (OpenAI Embeddings)")
    print("  3. ì½˜í…ì¸  ê¸°ë°˜ ìœ ì‚¬ë„ ë¶„ì„ (TF-IDF)")
    print("  4. í˜‘ì—… í•„í„°ë§ (ì‚¬ìš©ì ë°ì´í„° í•„ìš”)")
    print("  5. LLM í™œìš© ì¶”ì²œ (GPT-4, Claude)")

    return data


def test_keyword_search(data, keyword):
    """í‚¤ì›Œë“œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
    print(f"\nğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸: '{keyword}'")
    print("-" * 80)

    results = []
    keyword_lower = keyword.lower()

    for resource in data:
        score = 0

        # ì œëª©ì—ì„œ ê²€ìƒ‰
        if keyword_lower in resource['title'].lower():
            score += 3

        # ì„¤ëª…ì—ì„œ ê²€ìƒ‰
        if keyword_lower in resource.get('description', '').lower():
            score += 2

        # ê³¼ëª©ì—ì„œ ê²€ìƒ‰
        if keyword_lower in resource.get('subjects', '').lower():
            score += 1

        if score > 0:
            results.append((score, resource))

    # ì ìˆ˜ìˆœ ì •ë ¬
    results.sort(reverse=True, key=lambda x: x[0])

    print(f"ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ")
    print(f"\nìƒìœ„ 5ê°œ:")
    for i, (score, resource) in enumerate(results[:5], 1):
        print(f"\n{i}. [{resource['type']}] {resource['title']} (ì ìˆ˜: {score})")
        print(f"   ê³¼ëª©: {resource.get('subjects', 'N/A')}")
        print(f"   ì„¤ëª…: {resource.get('description', 'N/A')[:100]}...")


def main():
    data = analyze_data_quality()

    # í‚¤ì›Œë“œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    test_keywords = ['coding', 'math', 'science', 'AI', 'chemistry']

    print("\n" + "=" * 80)
    print("ğŸ§ª í‚¤ì›Œë“œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    print("=" * 80)

    for keyword in test_keywords[:2]:  # ì²˜ìŒ 2ê°œë§Œ í…ŒìŠ¤íŠ¸
        test_keyword_search(data, keyword)

    # ê²°ë¡ 
    print("\n" + "=" * 80)
    print("ğŸ“Œ ê²°ë¡ ")
    print("=" * 80)
    print("""
í˜„ì¬ ë°ì´í„°ë¡œ í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ì²œì´ ê°€ëŠ¥í•œê°€?

âœ… ê°€ëŠ¥í•¨! (ë‹¨, ì œí•œì )
- ê³¼ëª©, íƒ€ì…, ì œëª© ê¸°ë°˜ í•„í„°ë§ì€ ë§¤ìš° ì˜ ì‘ë™
- ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê²€ìƒ‰ì€ ì¶©ë¶„íˆ ê°€ëŠ¥
- SQLite FTS5ë¡œ ë¹ ë¥¸ ê²€ìƒ‰ ì§€ì›

âš ï¸ í•˜ì§€ë§Œ í’ˆì§ˆ ê°œì„ ì´ í•„ìš”í•¨:
- í˜„ì¬: ê¸°ë³¸ì ì¸ í‚¤ì›Œë“œ ë§¤ì¹­ ìˆ˜ì¤€
- ê°œì„  í›„: ì˜ë¯¸ ê¸°ë°˜ ì¶”ì²œ, ì»¨í…ìŠ¤íŠ¸ ì´í•´

ğŸš€ ì¶”ì²œ ê°œì„  ë‹¨ê³„:
1ë‹¨ê³„ (í˜„ì¬): í‚¤ì›Œë“œ + ê³¼ëª© í•„í„°ë§ âœ…
2ë‹¨ê³„: í¬ë¡¤ë§ìœ¼ë¡œ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
3ë‹¨ê³„: TF-IDF ìœ ì‚¬ë„ ë¶„ì„
4ë‹¨ê³„: ì„ë² ë”© ê¸°ë°˜ ì˜ë¯¸ ê²€ìƒ‰
5ë‹¨ê³„: LLM ê¸°ë°˜ ìì—°ì–´ ì¶”ì²œ

ì§€ê¸ˆ ë°”ë¡œ ë§Œë“¤ ìˆ˜ ìˆëŠ” ê²ƒ:
- ê¸°ë³¸ ê²€ìƒ‰ ì±—ë´‡ (í‚¤ì›Œë“œ + í•„í„°)
- ê³¼ëª©ë³„ ë¦¬ì†ŒìŠ¤ ë¸Œë¼ìš°ì €
- ê°„ë‹¨í•œ ì¶”ì²œ ì‹œìŠ¤í…œ
""")


if __name__ == "__main__":
    main()
